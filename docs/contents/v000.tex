\section{Ver. 0.0, revisions 1-X}

\subsection{Sorceress}
TODO framework

\subsubsection{Fibers and the job system}
This fiber-based job system is implemented based on ideas presented by Naughty Dog
in the GDC2025 talk ``Parallelizing the Naughty Dog Engine using Fibers''.

[Naughty Dog Video] 
\url{http://gdcvault.com/play/1022186/Parallelizing-the-Naughty-Dog-Engine}

Running this multithreaded, the work is not guaranteed to be executed in the order it was submitted.
That's the deal, for work to run in parallel. 
Yielding jobs doesn't ``block'' in the traditional sense, instead the current context of execution
is switched with a fiber that contains details of a new job to run.
These details include a function pointer, data as an argument to the function, 
a hint for how large the fiber stack should be and a name of the job for the fiber to inherit.
To yield one must acquire a chain. 
This chain can be bound to a submission, then the yielding fiber may not resume until all work bound to the chain is done.

Context switching is very CPU specific, so this functionality is written in assembly.
An implementation must be provided for every pair or CPU architecture, platform ABI and assembler to be supported.
A great deal of help in implementing this was the source code to Boost C++ fiber context library.
It has most of this stuff figured out for a lot of different targets.

[Boost::Context]
\url{https://github.com/boostorg/context}

[Fibers, Oh My!]
\url{https://graphitemaster.github.io/fibers/}

First call of jump\_fcontext() enters the context-function f1() by starting context fc1 (context fcm saves the registers of main()). 
For jumping between context's fc1 and fc2 jump\_fcontext() is called. 
Because context fcm is chained to fc1, main() is entered (returning from jump\_fcontext()) after context fc1 becomes complete (return from f1()).

In my last implementation of this job system in C, fiber stacks have been preallocated as a large flat array.
There was a lot of problems with this design. 
The memory usage was unnecessary, as fiber stacks had to be sized for worst case.
For example a stack size of 128 KiB was barely enough to call into vkCreateInstance() from the main context.

Fundamental to the fiber code is thread local storage (TLS). 
We are rolling out an array of such structures and assign them to threads by an \texttt{0..thread\_count} index.
The thread index runs on Zig's \texttt{threadlocal}. 

A deadlock happens if the MPMC ring buffer is full and running from only one thread.
This will also happen when dequeuing from an empty buffer on singlethreaded applications.
The waiting for enqueue/dequeue thread may never leave the loop 
when there is no other thread to try to empty/fill the buffer. 
This should not really be an issue unless stress testing the job system on singlethreaded environments.

May get into improving context switching prediction, if this can improve speed:
\url{http://www.crystalclearsoftware.com/soc/coroutine/coroutine/linuxasm.html}

\subsubsection{Drifter allocator}
Here I want to improve on that by making the fiber stacks dynamically allocated.
With that we'll be able to size every job for just as much stack space it needs to run.
I'll achieve this by implementing an allocator, here called \textit{drifter}, for transient resources bound to a fiber context.
Generally we make a double-ended stack where one end is for user-requested heap allocations (works like an arena allocator),
and the second end would be responsible of allocations for fiber stacks.
If a fiber yields, there are cases where the next fiber may inherit the drifter and make use of some unused stack space.

With the introduction of drifters, we must solve these problems:
\begin{itemize}
    \item \textbf{Undefined behaviour: fiber context.} 
        The context is saved on the stack from the top of an allocation, it's size is implementation dependend.
        This state must persist until after a thread jumps to the next fiber, only then the old fiber and context may be released.
        We assert for that, as we can't make a jump when home context's address is equal to new context's.
        If we try, we'll probably nuke the process this way by writing into a context state we were supposed to read from :D.
        This imposes challenges on reusing drifters for when the old fiber is freed, 
        and the next fiber is a new job so it doesn't have an idle drifter of their own to resume.
        We could solve this by either forcing every thread that runs a new job after freeing an old fiber to yield it's drifter,
        or by padding into the fiber stacks in a tricky way everytime this scenario happens.
    \item \textbf{Synchronization: fiber migrates between threads.}
        There is no guarantee, that thread who yields a fiber into the wait list will be the same thread to resume it later.
        We can't store the drifter in TLS, as it is supposed to migrate together with fibers.
        This is a synchronization problem, only one non-waiting fiber may own an unique drifter at a time.
        If we want to reuse the drifters to not waste any memory, these transitions must be resolved without conflicts.
    \item \textbf{Optimization: memory usage.}
        To minimalize problems that would come from dynamic allocations, the framework preallocates regions for drifters 
        large enough to run either a heavy fiber stack or a fine amount of transient resources, for a single job.
        This is already an improvement from removing per-fiber worst case scenario stacks and introducing the drifter.
        We can improve this further by keeping the number of drifters needed to run the system at minimum.
        I figured we'll need for sure one drifter per-thread. 
        If we implement stuff like described in the first point -- 
        to force every thread with a to free old fiber to yield it's drifter, to avoid stack corruption of the fiber context -- 
        or possibly other solutions that I must yet come up with, we'll need at maximum $2*\text{thread\_count}-1$ drifters.
        Ideal scenario would be one per thread ofc.
\end{itemize}

\subsection{Wayland}
The Wayland book is a great resource to figure out details of how to implement Wayland clients.
[wayland-book]\url{https://wayland-book.com/introduction.html}

The libwayland-client and libwayland-server libraries implement the wire protocol for each end of the connection.
These libraries also include some utilities for working with Wayland data structures, a simple event loop, and a pre-compiled copy of the core Wayland protocol.
Even though we have a low-level wayland protocol implementation at our hands, we still need to make things compatible with libwayland-client,
because Vulkan drivers still expect us to use it -- if we wan't to use the swapchain, that is.

There's also a great presentation in Zig made by Jonathan Marler for the X11 server, touching basically the same principles we'll be exploring via our Wayland backend (and X11 later).
[How to Use Abstraction to Kill Your API - Jonathan Marler - Software You Can Love Vancouver 2023]\url{https://www.youtube.com/watch?v=aPWFLkHRIAQ}

\subsubsection{The wire protocol}
[The Wayland Protocol, by Kristian HÃ¸gsberg]\url{https://wayland.freedesktop.org/docs/html/ch04.html#sect-Protocol-Wire-Format} \\
[The Wayland Protocol, by Drew DeVault]\url{https://wayland-book.com/protocol-design/wire-protocol.html}

The protocol is a stream of 32-bit values, encoded with a native endianess.
Using Wire we represent values as the following primitive types:
\begin{itemize}
    \item \textbf{int, uint}: 32-bit signed or unsigned integer.
    \item \textbf{fixed}: 24.8-bit signed fixed-point numbers.
    \item \textbf{object}: 32-bit object ID.
    \item \textbf{new\_id}: 32-bit object ID which allocates that object when received.
    \item \textbf{string}: Prefixed with a 32-bit integer specifying its length (in bytes),
        followed by the string contents and a NUL terminator, padded to 32 bits with undefined data.
        We'll be using the UTF-8 encoding.
    \item \textbf{array}: Prefixed with a 32-bit integer specifying its length (in bytes),
        then the verbatim contents of the array, padded to 32 bits with undefined data.
    \item \textbf{fd}: transfers a file descriptor to the other end using the ancillary data 
        in the UNIX domain socket message (msg\_control).
    \item \textbf{enum}: A single value (or bitmap) from an enumeration of known constants, encoded into a 32-bit integer.
\end{itemize}

\subsection
